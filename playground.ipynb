{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6f1423e-a07e-4869-b98a-cdebc245115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b153ed09-d210-4958-a64f-a101d4f1a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    # img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5efc6481-6895-4196-9d7e-c977372fa14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'example.png'\n",
    "processed_img = load_and_preprocess_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c73a34a-1102-4af4-961f-0b0457a6a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_reconstructed = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#   # tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#   tf.keras.layers.Flatten(),\n",
    "#   tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# print([layer.name for layer in model_reconstructed.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b8f6139-2d08-472f-ae40-3f7f3a2f0c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 21:03:03.069553: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 11075584 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# layer_file_names = ['conv2d', None, 'dense', 'dense_1']\n",
    "\n",
    "# for layer_file_name, layer in zip(layer_file_names, model_reconstructed.layers):\n",
    "#     if layer_file_name is None:\n",
    "#         continue\n",
    "\n",
    "#     weight_file = f'mnist_trained/{layer_file_name}_weights.npy'\n",
    "#     bias_file = f'mnist_trained/{layer_file_name}_biases.npy'\n",
    "    \n",
    "#     weights = np.load(weight_file)\n",
    "#     biases = np.load(bias_file)\n",
    "    \n",
    "#     layer.set_weights([weights, biases])\n",
    "\n",
    "# model_reconstructed.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39c83be1-0c9f-4be0-a59a-a9698e006eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_layers_descriptor = [\n",
    "    {'file_name': 'conv2d', 'activation': 'relu'}, \n",
    "    {'activation': 'flatten'}, \n",
    "    {'file_name': 'dense', 'activation': 'relu'}, \n",
    "    {'file_name': 'dense_1', 'activation': 'softmax'}\n",
    "]\n",
    "\n",
    "def load_weights_from_descriptor(layer_descriptor):\n",
    "    assert layer_descriptor\n",
    "    assert 'file_name' in layer_descriptor\n",
    "    \n",
    "    layer_file_name = layer_descriptor['file_name']\n",
    "    weight_file = f'mnist_trained/{layer_file_name}_weights.npy'\n",
    "    bias_file = f'mnist_trained/{layer_file_name}_biases.npy'\n",
    "\n",
    "    weights = np.load(weight_file)\n",
    "    biases = np.load(bias_file)\n",
    "\n",
    "    return { 'weights': weights, 'bias': biases, 'activation': layer_descriptor['activation'] }\n",
    "\n",
    "mnist_layers = [ load_weights_from_descriptor(layer_descriptor) if 'file_name' in layer_descriptor else layer_descriptor for layer_descriptor in student_model_layers_descriptor ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2968a587-4073-4d51-9a45-125bffa2751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 405ms/step\n",
      "Predicted class: [2]\n"
     ]
    }
   ],
   "source": [
    "# prediction = model_reconstructed.predict(processed_img)\n",
    "from src.forward_propagation import forward_propagation\n",
    "\n",
    "student_model = forward_propagation(mnist_layers)\n",
    "\n",
    "prediction = student_model(processed_img)\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
